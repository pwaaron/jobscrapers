{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MyCareersFuture.SG API Calls\n",
    "This runs much faster than manually running a automated web driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "API_LINK = 'https://api1.mycareersfuture.sg/v2/jobs?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to change\n",
    "Please change the *search query* and the *number of total jobs* you would like to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []\n",
    "LIMIT = 100 # Limit should not exceed 100. The smaller the number, the gentler it is\n",
    "SEARCH_QUERY = '' #search query\n",
    "TOTAL_JOBS = 20 * 1178 # Number of jobs to be queried\n",
    "N_PAGES = TOTAL_JOBS//LIMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For limited queries\n",
    "for page in range(N_PAGES):\n",
    "    query = {'limit': LIMIT, 'page': page, 'search': SEARCH_QUERY}\n",
    "    r = requests.get(API_LINK + urlencode(query))\n",
    "    jobs.extend(r.json()[\"results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To query all pages\n",
    "page = 0 \n",
    "query = {'limit': LIMIT, 'page': page, 'search': SEARCH_QUERY}\n",
    "r = requests.get(API_LINK + urlencode(query))\n",
    "\n",
    "while r.json()[\"results\"]:\n",
    "    jobs.extend(r.json()[\"results\"])\n",
    "    page += 1\n",
    "    query = {'limit': LIMIT, 'page': page, 'search': SEARCH_QUERY}\n",
    "    r = requests.get(API_LINK + urlencode(query))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Information Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = list(map(lambda job: job['uuid'], jobs))\n",
    "ext_job_id = list(map(lambda job: job['metadata']['jobPostId'], jobs))\n",
    "job_title = list(map(lambda job: job['title'], jobs))\n",
    "job_description = list(map(lambda job: BeautifulSoup(job['description'], 'lxml').text, jobs))\n",
    "minimum_years_experience = list(map(lambda job: job['minimumYearsExperience'], jobs))\n",
    "ssoc_code = list(map(lambda job: job['ssocCode'], jobs))\n",
    "categories = list(map(lambda job: '; '.join(list(map(lambda category: category['category'], job['categories']))), jobs))\n",
    "employment_types = list(map(lambda job: '; '.join(list(map(lambda employmentType: employmentType['employmentType'], job['employmentTypes']))), jobs))\n",
    "position_levels = list(map(lambda job: '; '.join(list(map(lambda positionLevel: positionLevel['position'], job['positionLevels']))), jobs))\n",
    "skills = list(map(lambda job: '; '.join(list(map(lambda skill: skill['skill'], job['skills']))), jobs))\n",
    "organisation = list(map(lambda job: job['postedCompany']['name'], jobs))\n",
    "last_updated = list(map(lambda job: job['metadata']['updatedAt'], jobs))\n",
    "salary_minimum = list(map(lambda job: job['salary']['minimum'], jobs))\n",
    "salary_maximum = list(map(lambda job: job['salary']['maximum'], jobs))\n",
    "salary_type = list(map(lambda job: job['salary']['type']['salaryType'], jobs))\n",
    "api_link = list(map(lambda job: job['_links']['self']['href'], jobs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as Dataframe and Export as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = {'job_id': job_id, 'ext_job_id': ext_job_id, \n",
    "       'job_title': job_title, 'job_description': job_description,\n",
    "       'minimum_years_experience': minimum_years_experience, \n",
    "       'ssoc_code': ssoc_code, 'categories': categories, \n",
    "       'employment_types': employment_types, 'position_levels': position_levels,\n",
    "       'skills': skills, 'organisation': organisation,\n",
    "       'salary_minimum': salary_minimum, 'salary_maximum': salary_maximum, 'salary_type': salary_type,\n",
    "       'api_link': api_link, 'last_updated': last_updated}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.DataFrame(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"mycareersfuturesg_results\" + \".csv\" # change filename\n",
    "jobs.to_csv(FILENAME, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
